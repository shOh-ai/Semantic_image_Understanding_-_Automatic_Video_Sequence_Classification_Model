# -*- coding: utf-8 -*-
"""Chapter 1. Transfer learning.ipynb의 사본

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j7JAuxjPKf9K7xePfE-vI-T8WppV0RD5
"""

import sys
import os
import cv2
import time
import copy
import numpy as np
import matplotlib.pyplot as plt
import torch
from torch.utils.data import Dataset

import torch.nn as nn
import torch.optim as optim

from torchvision import datasets, models, transforms

from google.colab import drive
drive.mount('/content/drive')

!pip install -U openmim
!pip install timm==0.6.11 mmdet==2.28.1
!pip install opencv-python termcolor yacs pyyaml scipy

"""## Clone a github repository"""

!rm -rf InternImage
!git clone https://github.com/OpenGVLab/InternImage.git

cd InternImage

!pwd

my_path = '/content/packages'
save_path = '/content/drive/MyDrive/Colab Notebooks/packages' ## 패키지가 저장될 경로

os.symlink(save_path, my_path)
sys.path.insert(0, my_path)

#!pip install --target=$my_path mmcv-full==1.5.0

import mmcv

"""## test data code 수정(videodataset class 삽입, option 받을 수 있도록 수정)"""

from google.colab import files
uploaded = files.upload()

!pip install 'DCNv3-1.0+cu116torch1.12.0-cp310-cp310-linux_x86_64.whl'

!python detection/test.py configs/coco/cascade_internimage_xl_fpn_1x_coco.py checkpoint_dir/det/cascade_internimage_xl_fpn_1x_coco.pth --eval bbox segm --eval-options "custom_data=${custom_test_data}"

class VideoDataset(Dataset):
    def __init__(self, video_paths, labels=None, transform=None):
        self.video_paths = video_paths
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.video_paths)

    def __getitem__(self, idx):
        video_path = self.video_paths[idx]
        label = self.labels[idx] if self.labels else None

        # Load the video and extract frames
        cap = cv2.VideoCapture(video_path)
        frames = []
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            frames.append(frame_rgb)
        cap.release()

        # Apply the transformations
        if self.transform:
            frames = [self.transform(frame) for frame in frames]

        # Stack the frames along the time dimension
        frames_tensor = torch.stack(frames)

        return (frames_tensor, label) if label is not None else frames_tensor

# 비디오 파일이 저장된 디렉토리
video_directory = "/content/drive/MyDrive/Europe_vlog"

# 비디오 경로 생성 (Europe_vlog.mov 파일만 사용하려면)
video_paths = [os.path.join(video_directory, video_name) for video_name in os.listdir(video_directory) if video_name == 'Europe_vlog.mov']

# 위에서 정의한 VideoDataset 클래스 사용
dataset = VideoDataset(video_paths, labels=None)

print(sys.version)
print("Torch version:{}".format(torch.__version__))
print("cuda version: {}".format(torch.version.cuda))
print("cudnn version:{}".format(torch.backends.cudnn.version()))

!pip install torch torchvision

import torchvision

pip install torch==2.0.0+cu118 torchvision==0.12.0+cu113

"""## Pre-trained model download"""

#!wget https://github.com/OpenGVLab/InternImage/blob/master/detection/configs/coco/cascade_internimage_xl_fpn_1x_coco.py